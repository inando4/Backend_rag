import json
import os
import faiss
import re
import unicodedata
import socket
import time
import logging
import requests
from sentence_transformers import SentenceTransformer
from collections import defaultdict
from django.conf import settings

logger = logging.getLogger(__name__)

class RAGService:
    def __init__(self):
        # Rutas de archivos
        self.base_path = os.path.join(settings.BASE_DIR, 'data')
        self.json_path = os.path.join(self.base_path, 'dataset_v2.json')
        self.index_path = os.path.join(self.base_path, 'index.faiss')
        
        # Inicializar modelo de embeddings
        self.model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')
        
        # ‚úÖ Configuraci√≥n LLM (SOLO LOCAL)
        self.ollama_model = os.getenv('OLLAMA_MODEL', 'qwen2.5:14b-instruct')
        self.ollama_url = "http://localhost:11434/api/generate"
        
        # Cargar datos y crear √≠ndice
        self.documents = self.load_documents()
        self.index = self.load_or_create_index()
        
        logger.info(f"‚úÖ RAG Service iniciado")
        logger.info(f"   Modelo Ollama: {self.ollama_model}")
    
    def load_documents(self):
        """Cargar documentos desde JSON"""
        try:
            with open(self.json_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"Error: No se encontr√≥ {self.json_path}")
            return []
    
    def load_or_create_index(self):
        """Cargar √≠ndice existente o crear uno nuevo"""
        if os.path.exists(self.index_path):
            return faiss.read_index(self.index_path)
        else:
            return self.create_index()
    
    def create_index(self):
        """Crear √≠ndice FAISS"""
        if not self.documents:
            return None
        
        # Crear embeddings
        texts = [doc['content'] for doc in self.documents]
        embeddings = self.model.encode(texts)
        
        # Crear √≠ndice FAISS
        dimension = embeddings.shape[1]
        index = faiss.IndexFlatIP(dimension)
        
        # Normalizar embeddings para similitud coseno
        faiss.normalize_L2(embeddings)
        index.add(embeddings)
        
        # Guardar √≠ndice
        os.makedirs(self.base_path, exist_ok=True)
        faiss.write_index(index, self.index_path)
        
        return index
    
    def keyword_search(self, query, documents):
        """B√∫squeda por palabras clave mejorada con sin√≥nimos"""
        
        def normalize(text):
            text = unicodedata.normalize('NFD', text)
            text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
            return text.lower()
        
        query_normalized = normalize(query)
        query_words = query_normalized.split()
        
        # Sin√≥nimos del dominio AMPLIADOS
        synonyms = {
            'matricula': ['matricula', 'inscripcion', 'registro'],
            'convalidacion': ['convalidacion', 'validacion', 'reconocimiento'],
            'excepcion': ['excepcion', 'especial', 'extraordinaria'],
            'requisitos': ['requisitos', 'documentos', 'expediente'],
            'cronograma': ['cronograma', 'fecha', 'fechas', 'calendario', 'plazo', 'cuando', 'cuanto'],
            'reserva': ['reserva', 'suspension', 'pausa'],
            'reactualizacion': ['reactualizacion', 'reactivacion', 'renovacion'],
            'presentar': ['presentar', 'entregar', 'donde', 'lugar'],
            'expediente': ['expediente', 'tramite', 'solicitud', 'documento'],
            'criterios': ['criterios', 'requisitos', 'condiciones', 'exigencias'],
            'academicos': ['academicos', 'academicas', 'educativos', 'curriculares'],
            'creditaje': ['creditaje', 'creditos', 'credito', 'unidades'],
            'contenidos': ['contenidos', 'contenido', 'temas', 'silabo', 'programa'],
            'similitud': ['similitud', 'equivalencia', 'parecido', 'semejanza'],
            'institutos': ['institutos', 'instituto', 'cetpro', 'senati', 'sencico'],
            'restricciones': ['restricciones', 'limitaciones', 'prohibiciones', 'no se puede', 'no se permite'],
            'pueden': ['pueden', 'puede', 'se puede', 'es posible', 'permiten'],
            'costo': ['costo', 'precio', 'pago', 'tasa', 'tarifa', 'cuanto cuesta', 'cuanto es', 'valor', 'monto'],
            'modalidad': ['modalidad', 'tipo', 'categoria', 'ordinario', 'profesional', 'ceprunsa', 'traslado'],
            'validar': ['validar', 'validacion', 'confirmar', 'confirmacion'],
            'obligatorio': ['obligatorio', 'obligatoriamente', 'debe', 'requerido', 'necesario'],
            'finalizar': ['finalizar', 'terminar', 'culminar', 'concluir', 'completar'],
            'constancia': ['constancia', 'documento', 'comprobante', 'certificado'],
            'imprimir': ['imprimir', 'descargar', 'obtener'],
            # ‚úÖ NUEVOS SIN√ìNIMOS PARA PREGUNTAS CONCEPTUALES
            'acto': ['acto', 'accion', 'procedimiento', 'proceso', 'tramite'],
            'formal': ['formal', 'oficial', 'administrativo'],
            'acredita': ['acredita', 'certifica', 'avala', 'valida', 'reconoce'],
            'condicion': ['condicion', 'estado', 'situacion', 'calidad'],
            'definicion': ['que es', 'cual es', 'define', 'definicion', 'concepto', 'significa']
        }
        
        # Expandir query con sin√≥nimos
        expanded_words = set(query_words)
        for word in query_words:
            for key, syn_list in synonyms.items():
                if word in syn_list:
                    expanded_words.update(syn_list)
        
        # Detectar tipo de pregunta
        date_question = any(w in query_normalized for w in ['cuando', 'fecha', 'fechas', 'plazo', 'cronograma'])
        place_question = any(w in query_normalized for w in ['donde', 'lugar', 'presentar', 'entregar'])
        academic_question = any(w in query_normalized for w in ['criterios', 'requisitos', 'academico', 'creditaje', 'contenido', 'similitud'])
        restriction_question = any(w in query_normalized for w in ['se pueden', 'se puede', 'puedo', 'permiten', 'permite', 'instituto', 'restriccion', 'prohibido', 'no se'])
        cost_question = any(w in query_normalized for w in ['cuanto', 'cuesta', 'costo', 'precio', 'pago', 'tasa', 'tarifa', 'valor', 'monto', 's/'])
        
        validation_question = any(w in query_normalized for w in [
            'validar', 'validacion', 'finalizar', 'terminar', 'culminar', 
            'obligatorio', 'obligatoriamente', 'debe', 'despues de registrar',
            'al finalizar', 'al terminar', 'constancia'
        ])
        
        # ‚úÖ NUEVO: Detectar preguntas CONCEPTUALES/DEFINICIONES
        definition_question = any(phrase in query_normalized for phrase in [
            'que es', 'cual es', 'que significa', 'define', 'definicion',
            'concepto', 'se considera', 'se entiende por',
            'acto formal', 'acto voluntario', 'acredita la condicion'
        ])
        
        # Detectar preguntas sobre FORMA/PROCEDIMIENTO de pago
        payment_procedure_question = any(w in query_normalized for w in [
            'varios recibos', 'un solo recibo', 'un recibo', 'varios pagos', 
            'puedo pagar', 'como pago', 'forma de pago', 'procedimiento de pago',
            'en cuotas', 'en partes', 'fraccionado'
        ])
        
        # Detectar preguntas espec√≠ficas sobre MONTOS
        amount_question = any(w in query_normalized for w in [
            'cuanto cuesta', 'cuanto es', 'cual es el costo', 'cual es el precio',
            'monto', 'valor', 's/', 'soles'
        ])
        
        keyword_scores = defaultdict(float)
        
        for i, doc in enumerate(documents):
            content_normalized = normalize(doc['content'])
            score = 0
            
            # ‚úÖ L√ìGICA ESPECIAL PARA PREGUNTAS CONCEPTUALES
            if definition_question:
                # Palabras clave para definiciones
                definition_keywords = [
                    'es el acto', 'se considera', 'se define', 'definicion',
                    'acto formal', 'acto voluntario', 'acredita', 'condicion de estudiante',
                    'articulo 3', 'articulo 4', 'articulo'
                ]
                
                # Si la pregunta menciona "acto formal" + "acredita" + "condici√≥n"
                if 'acto formal' in query_normalized and 'acredita' in query_normalized:
                    # Buscar documentos que tengan EXACTAMENTE esa combinaci√≥n
                    if 'acto formal' in content_normalized and 'acredita' in content_normalized and 'condicion de estudiante' in content_normalized:
                        score = 3000  # Score MUY ALTO para match exacto
                        logger.info(f"    üéØ Definici√≥n EXACTA encontrada en {doc.get('id_chunk')}")
                    else:
                        score = 50  # Score bajo si no tiene la definici√≥n exacta
                else:
                    # Para otras preguntas conceptuales, buscar keywords generales
                    matches = sum(1 for kw in definition_keywords if kw in content_normalized)
                    if matches > 0:
                        score = 2000 + (matches * 200)
                        logger.info(f"    ‚úÖ Definici√≥n encontrada en {doc.get('id_chunk')}: {matches} keywords")
                    else:
                        score = 20
                
                keyword_scores[i] = score
                continue
            
            # L√ìGICA ESPECIAL PARA PREGUNTAS DE VALIDACI√ìN
            if validation_question:
                validation_keywords = [
                    'validar', 'validacion', 'validar su matricula',
                    'obligatorio', 'obligado', 'debe',
                    'constancia', 'imprimir', 'finalizar', 'finalmente'
                ]
                
                matches = sum(1 for kw in validation_keywords if kw in content_normalized)
                
                if matches > 0:
                    score = 2000 + (matches * 200)
                    logger.info(f"    ‚úÖ Validaci√≥n encontrada en {doc.get('id_chunk')}: {matches} keywords")
                else:
                    score = 10
                
                keyword_scores[i] = score
                continue
            
            # L√ìGICA ESPECIAL PARA PREGUNTAS DE COSTOS
            if cost_question:
                if payment_procedure_question:
                    payment_keywords = ['recibo', 'recibos', 'un solo', 'todas las asignaturas', 'monto total', 'pago']
                    keyword_count = sum(1 for kw in payment_keywords if kw in content_normalized)
                    
                    if keyword_count > 0:
                        score = 2000 + (keyword_count * 100)
                        logger.info(f"    ‚úÖ Procedimiento de pago encontrado en {doc.get('id_chunk')}: {keyword_count} keywords")
                    else:
                        score = 5
                    
                    keyword_scores[i] = score
                    continue
                
                elif amount_question:
                    if 'tasa_soles' not in doc or not doc.get('tasa_soles'):
                        keyword_scores[i] = 0
                        continue
                    
                    score = 1000
                    
                    modalidades_en_query = []
                    if 'ordinario' in query_normalized:
                        modalidades_en_query.append('ordinario')
                    if 'profesional' in query_normalized or 'profesionales' in query_normalized:
                        modalidades_en_query.append('profesionales')
                    if 'ceprunsa' in query_normalized:
                        modalidades_en_query.append('ceprunsa')
                    if 'traslado' in query_normalized:
                        modalidades_en_query.append('traslado')
                    
                    procedencias_en_query = []
                    if 'otra escuela' in query_normalized or 'escuela unsa' in query_normalized:
                        procedencias_en_query.append('otra_escuela_unsa')
                    if 'universidad nacional' in query_normalized and 'otra' in query_normalized:
                        procedencias_en_query.append('universidad_nacional_otra')
                    if 'universidad particular' in query_normalized or 'universidad privada' in query_normalized:
                        procedencias_en_query.append('universidad_particular')
                    
                    doc_modalidad_value = doc.get('modalidad_pago_relacionada', '')
                    if doc_modalidad_value:
                        doc_modalidad_norm = normalize(doc_modalidad_value)
                        
                        modalidad_match = False
                        procedencia_match = False
                        
                        for modalidad in modalidades_en_query:
                            if modalidad in doc_modalidad_norm:
                                modalidad_match = True
                                score += 500
                                logger.info(f"    ‚úÖ Modalidad '{modalidad}' encontrada en {doc.get('id_chunk')}")
                                break
                        
                        if 'universidad_particular' in procedencias_en_query:
                            if 'universidad particular' in doc_modalidad_norm:
                                procedencia_match = True
                                score += 800
                                logger.info(f"    ‚úÖ Procedencia 'universidad particular' encontrada en {doc.get('id_chunk')}")
                        elif 'universidad_nacional_otra' in procedencias_en_query:
                            if 'universidad nacional' in doc_modalidad_norm and 'otra' in doc_modalidad_norm:
                                procedencia_match = True
                                score += 800
                                logger.info(f"    ‚úÖ Procedencia 'universidad nacional (otra)' encontrada en {doc.get('id_chunk')}")
                        elif 'otra_escuela_unsa' in procedencias_en_query:
                            if 'otra escuela de la unsa' in doc_modalidad_norm or 'escuela de la unsa' in doc_modalidad_norm:
                                procedencia_match = True
                                score += 800
                                logger.info(f"    ‚úÖ Procedencia 'otra escuela UNSA' encontrada en {doc.get('id_chunk')}")
                        
                        if modalidades_en_query and not modalidad_match:
                            score = 10
                            logger.info(f"    ‚ùå Modalidad NO coincide en {doc.get('id_chunk')}: '{doc_modalidad_value}'")
                        
                        if procedencias_en_query and not procedencia_match:
                            score = score * 0.05
                            logger.info(f"    ‚ùå Procedencia NO coincide en {doc.get('id_chunk')}: '{doc_modalidad_value}'")
                    
                    keyword_scores[i] = score
                    continue
                
                else:
                    if 'tasa_soles' in doc and doc.get('tasa_soles'):
                        score = 1000
                    elif any(kw in content_normalized for kw in ['recibo', 'pago', 'un solo', 'todas las asignaturas']):
                        score = 1500
                    else:
                        score = 0
                    
                    keyword_scores[i] = score
                    continue
            
            # Para preguntas NO especiales, usar l√≥gica normal
            for word in expanded_words:
                if word in content_normalized:
                    count = content_normalized.count(word)
                    score += count * 2
            
            if query_normalized in content_normalized:
                score += 30
            
            # BONUS para preguntas sobre RESTRICCIONES
            if restriction_question:
                restriction_keywords = ['no se convalidan', 'restriccion', 'prohibido', 'no se permite', 'instituto', 'institutos', 'obligatorio']
                for kw in restriction_keywords:
                    if kw in content_normalized:
                        score += 60
                
                if 'sub_categoria' in doc:
                    sub_cat_value = doc.get('sub_categoria', '')
                    if sub_cat_value:
                        sub_cat = normalize(sub_cat_value)
                        if 'restriccion' in sub_cat or 'limitacion' in sub_cat:
                            score += 70
                
                negation_patterns = [
                    r'no se convalidan',
                    r'no se puede',
                    r'no se permite',
                    r'prohibido',
                    r'es obligatorio'
                ]
                
                for pattern in negation_patterns:
                    if re.search(pattern, content_normalized):
                        score += 50
            
            # BONUS para preguntas sobre criterios acad√©micos
            if academic_question:
                academic_keywords = ['creditaje', 'creditos', 'similitud', '80%', 'contenido', 'igual', 'mayor']
                for kw in academic_keywords:
                    if kw in content_normalized:
                        score += 40
                
                if 'sub_categoria' in doc:
                    sub_cat_value = doc.get('sub_categoria', '')
                    if sub_cat_value and 'academico' in normalize(sub_cat_value):
                        score += 50
            
            # BONUS EXTRA para documentos con fechas
            if date_question:
                date_patterns = [
                    r'\d{1,2}\s+de\s+\w+',
                    r'del\s+\d{1,2}\s+al\s+\d{1,2}',
                    r'\d{1,2}\s*[-/]\s*\d{1,2}',
                ]
                
                for pattern in date_patterns:
                    if re.search(pattern, content_normalized):
                        score += 50
                        break
                
                if 'fecha_relevante' in doc and doc['fecha_relevante']:
                    score += 40
                
                if 'actividad_cronograma' in doc and doc['actividad_cronograma']:
                    score += 30
            
            # BONUS EXTRA para documentos con lugares
            if place_question:
                place_keywords = ['escuela', 'oficina', 'caja', 'lugar', 'presentar', 'entregar']
                for kw in place_keywords:
                    if kw in content_normalized:
                        score += 20
                
                if 'lugar_pago' in doc and doc['lugar_pago']:
                    score += 35
            
            # Bonus por keywords del documento
            if 'keywords' in doc:
                for kw in doc.get('keywords', []):
                    if normalize(kw) in query_normalized:
                        score += 10
            
            # Bonus por categor√≠a relevante
            if 'categoria_principal' in doc:
                categoria_value = doc.get('categoria_principal', '')
                if categoria_value:
                    categoria = normalize(categoria_value)
                    if any(w in categoria for w in expanded_words):
                        score += 15
            
            keyword_scores[i] = score
            
        return keyword_scores
    
    def search_documents(self, query, top_k=5):
        """B√∫squeda h√≠brida: sem√°ntica + palabras clave"""
        if not self.index or not self.documents:
            return []
        
        # B√∫squeda sem√°ntica
        query_embedding = self.model.encode([query])
        faiss.normalize_L2(query_embedding)
        scores, indices = self.index.search(query_embedding, top_k * 3)
        
        # B√∫squeda por palabras clave
        keyword_scores = self.keyword_search(query, self.documents)
        
        # Detectar tipo de pregunta
        query_lower = query.lower()
        is_date_query = any(w in query_lower for w in ['cuando', 'fecha', 'fechas', 'plazo', 'cronograma'])
        is_place_query = any(w in query_lower for w in ['donde', 'lugar', 'presentar', 'entregar'])
        is_restriction_query = any(w in query_lower for w in ['se pueden', 'se puede', 'puedo', 'permiten', 'permite', 'instituto', 'restriccion', 'prohibido'])
        is_cost_query = any(w in query_lower for w in ['cuanto', 'cuesta', 'costo', 'precio', 'pago', 'tasa', 'tarifa', 'valor', 'monto', 's/'])
        is_validation_query = any(w in query_lower for w in ['validar', 'validacion', 'finalizar', 'terminar', 'obligatorio', 'obligatoriamente', 'constancia', 'al finalizar'])
        # ‚úÖ NUEVO
        is_definition_query = any(phrase in query_lower for phrase in ['que es', 'cual es', 'que significa', 'define', 'definicion', 'concepto', 'acto formal', 'acredita la condicion'])
        
        # Combinar puntuaciones
        combined_results = []
        for i, score in enumerate(scores[0]):
            if score > 0.2:
                doc_idx = indices[0][i]
                semantic_score = float(score)
                keyword_score = keyword_scores.get(doc_idx, 0)
                
                # Ajustar pesos din√°micamente
                if is_definition_query:  # ‚úÖ NUEVO - Keywords dominan totalmente
                    combined_score = (semantic_score * 0.05) + (keyword_score * 0.95)  # 95% keywords
                elif is_validation_query:
                    combined_score = (semantic_score * 0.1) + (keyword_score * 0.9)
                elif is_cost_query:
                    combined_score = (semantic_score * 0.2) + (keyword_score * 0.8)
                elif is_restriction_query:
                    combined_score = (semantic_score * 0.3) + (keyword_score * 0.7)
                elif is_date_query or is_place_query:
                    combined_score = (semantic_score * 0.4) + (keyword_score * 0.6)
                else:
                    combined_score = (semantic_score * 0.7) + (keyword_score * 0.3)
                
                combined_results.append({
                    'documento': self.documents[doc_idx],
                    'score': combined_score,
                    'semantic_score': semantic_score,
                    'keyword_score': keyword_score
                })
        
        # Ordenar por puntuaci√≥n combinada
        combined_results.sort(key=lambda x: x['score'], reverse=True)
        
        # Logging mejorado
        logger.info(f"üìä Query type - Fechas: {is_date_query}, Lugares: {is_place_query}, Restricciones: {is_restriction_query}, Costos: {is_cost_query}, Validaci√≥n: {is_validation_query}, Definici√≥n: {is_definition_query}")
        logger.info(f"üìä Recuperados {len(combined_results[:top_k])} documentos para: {query[:50]}...")
        
        for i, doc in enumerate(combined_results[:top_k], 1):
            logger.info(f"  {i}. Score: {doc['score']:.2f} (Sem: {doc['semantic_score']:.2f}, KW: {doc['keyword_score']:.2f})")
        
        return combined_results[:top_k]
    
    def _ensure_ollama_running(self):
        """Verificar que Ollama est√© corriendo"""
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            result = sock.connect_ex(('localhost', 11434))
            sock.close()
            
            if result == 0:
                logger.info("‚úÖ Ollama est√° corriendo")
                return True
            else:
                logger.warning("‚ö†Ô∏è Ollama no est√° corriendo")
                logger.info("üí° Inicia Ollama con: ollama serve")
                return False
                
        except Exception as e:
            logger.error(f"Error verificando Ollama: {e}")
            return False
    
    def _build_prompt(self, query, context):
        """Construir prompt optimizado"""
        return f"""Eres un asistente especializado en normativas acad√©micas de la Universidad Nacional de San Agust√≠n (UNSA).

CONTEXTO (m√∫ltiples documentos relacionados):
{context}

PREGUNTA DEL ESTUDIANTE: {query}

INSTRUCCIONES CR√çTICAS:

1. **LEE CUIDADOSAMENTE** cada documento del contexto - est√°n numerados (DOCUMENTO 1, DOCUMENTO 2, etc.)

2. **EXTRAE INFORMACI√ìN ESPEC√çFICA** seg√∫n la pregunta:
   - Si preguntan "D√ìNDE": Busca en "üìç Lugar" o en el contenido principal
   - Si preguntan "CU√ÅNDO/FECHAS": Busca en "üìÖ FECHAS" 
   - Si preguntan "CU√ÅNTO/COSTO": Busca en "üí∞ Costo"

3. **NO MEZCLES INFORMACI√ìN** de diferentes documentos:
   - Un documento sobre "Presentaci√≥n de expedientes" NO es lo mismo que "Pago"
   - Un documento sobre "Lugar de pago" NO es el lugar de presentaci√≥n del expediente

4. **PRIORIZA** el documento m√°s relevante,el DOCUMENTO 1 es el M√ÅS RELEVANTE para esta pregunta.
   - Si el DOCUMENTO 1 contiene la respuesta completa, √öSALO y NO mezcles con otros documentos.
   - Solo usa otros documentos si el DOCUMENTO 1 no tiene informaci√≥n suficiente.

5. **FORMATO DE RESPUESTA**:
   - Responde de forma directa y estructurada
   - Si hay fechas, escr√≠belas como: "Del **17 de marzo** al **28 de marzo**"
   - Si hay lugares, especifica claramente: "en [lugar exacto]"
   - Si hay costos, menci√≥nalos: "S/ [monto]"
   - Brinda la informaci√≥n sin mencionar los documentos de donde la extraiste.

6. **PROHIBIDO**:
   - Inventar informaci√≥n que no est√© en el contexto
   - Mezclar informaci√≥n de documentos diferentes
   - Usar plantillas como "[d√≠a] de [mes]"

7. Si NO encuentras informaci√≥n espec√≠fica en el contexto, di: "No encontr√© informaci√≥n sobre [tema espec√≠fico]"

RESPUESTA:"""
    
    def _validate_dates_in_response(self, response, context):
        """Validar que las fechas mencionadas existan en el contexto"""
        # Extraer fechas de la respuesta
        date_patterns = [
            r'\d{1,2}\s+de\s+\w+',
            r'del\s+\d{1,2}\s+al\s+\d{1,2}',
        ]
        
        response_dates = []
        for pattern in date_patterns:
            response_dates.extend(re.findall(pattern, response.lower()))
        
        # Verificar que cada fecha est√© en el contexto
        context_lower = context.lower()
        hallucinated_dates = []
        
        for date in response_dates:
            if date not in context_lower:
                hallucinated_dates.append(date)
                logger.warning(f"‚ö†Ô∏è FECHA ALUCINADA DETECTADA: '{date}' no est√° en el contexto")
        
        if hallucinated_dates:
            logger.error(f"‚ùå El LLM invent√≥ fechas: {hallucinated_dates}")
            return False
        
        return True
    
    def _clean_response(self, response):
        """Limpiar respuesta de referencias a documentos internos"""
        # Eliminar referencias a "DOCUMENTO X"
        response = re.sub(r'Seg√∫n el DOCUMENTO \d+[^,.:]*,?\s*', '', response, flags=re.IGNORECASE)
        response = re.sub(r'En el DOCUMENTO \d+[^,.:]*,?\s*', '', response, flags=re.IGNORECASE)
        response = re.sub(r'El DOCUMENTO \d+[^,.:]*\s+(indica|dice|menciona|establece)\s+que\s*', '', response, flags=re.IGNORECASE)
        
        # Eliminar c√≥digos entre corchetes
        response = re.sub(r'\[CONV-[A-Z0-9-]+\]', '', response)
        response = re.sub(r'\[MAT-[A-Z0-9-]+\]', '', response)
        response = re.sub(r'\[RES-[A-Z0-9-]+\]', '', response)
        
        # Eliminar frases como "seg√∫n el contexto proporcionado"
        response = re.sub(r'Seg√∫n el contexto proporcionado,?\s*', '', response, flags=re.IGNORECASE)
        response = re.sub(r'Bas√°ndome en la informaci√≥n proporcionada,?\s*', '', response, flags=re.IGNORECASE)
        response = re.sub(r'De acuerdo (al|con el) contexto,?\s*', '', response, flags=re.IGNORECASE)
        
        # Limpiar espacios m√∫ltiples
        response = re.sub(r'\s+', ' ', response)
        
        return response.strip()
    
    def _generate_with_ollama(self, prompt, context=None, max_retries=2):
        """Generar respuesta con Ollama local"""
        
        if not self._ensure_ollama_running():
            raise Exception("Ollama no est√° disponible. Ejecuta: ollama serve")
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ü§ñ Generando con {self.ollama_model} (intento {attempt + 1}/{max_retries})...")
                start_time = time.time()
                
                response = requests.post(
                    self.ollama_url,
                    json={
                        "model": self.ollama_model,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.0 if attempt > 0 else 0.1,
                            "num_predict": 1500,
                            "top_p": 0.8
                        }
                    },
                    timeout=180
                )
                
                elapsed = time.time() - start_time
                logger.info(f"‚è±Ô∏è Tiempo: {elapsed:.2f}s")
                
                if response.status_code == 200:
                    answer = response.json()['response'].strip()
                    
                    # Limpiar respuesta
                    answer = re.sub(r'<think>.*?</think>', '', answer, flags=re.DOTALL)
                    answer = re.sub(r'<[^>]+>', '', answer)
                    answer = self._clean_response(answer)
                    
                    # Validar fechas si tenemos contexto
                    if context and self._validate_dates_in_response(answer, context):
                        return answer
                    elif not context:
                        return answer
                    else:
                        if attempt < max_retries - 1:
                            logger.warning("‚ö†Ô∏è Reintentando con instrucciones m√°s estrictas...")
                            prompt = prompt.replace(
                                "INSTRUCCIONES CR√çTICAS:",
                                "‚ö†Ô∏è ADVERTENCIA: Tu respuesta anterior conten√≠a fechas incorrectas. INSTRUCCIONES CR√çTICAS:"
                            )
                            continue
                        else:
                            logger.error("‚ùå M√°ximo de reintentos alcanzado.")
                            return answer
                else:
                    raise Exception(f"Ollama error: {response.status_code}")
                    
            except Exception as e:
                logger.error(f"Error en Ollama: {e}")
                if attempt == max_retries - 1:
                    raise
        
        return answer
    
    def generate_response(self, query, context_docs):
        """Generar respuesta usando Ollama local"""
        try:
            # Construir contexto ENRIQUECIDO
            context_parts = []
            
            for idx, doc_wrapper in enumerate(context_docs, 1):
                doc = doc_wrapper['documento']
                
                doc_lines = []
                
                # Agregar ENCABEZADO del documento
                header = f"DOCUMENTO {idx}"
                if doc.get('id_chunk'):
                    header += f" [{doc['id_chunk']}]"
                if doc.get('categoria_principal'):
                    header += f" - {doc['categoria_principal']}"
                if doc.get('sub_categoria'):
                    header += f" > {doc['sub_categoria']}"
                
                doc_lines.append(header)
                doc_lines.append("-" * 50)
                
                # Agregar METADATA estructurada
                if doc.get('actividad_cronograma'):
                    doc_lines.append(f"üìå Actividad: {doc['actividad_cronograma']}")
                
                if doc.get('fecha_relevante'):
                    doc_lines.append(f"üìÖ FECHAS: {doc['fecha_relevante']}")
                
                if doc.get('lugar_pago'):
                    doc_lines.append(f"üìç Lugar de pago: {doc['lugar_pago']}")
                
                if doc.get('tasa_soles'):
                    doc_lines.append(f"üí∞ Costo: S/ {doc['tasa_soles']}")
                
                if any([doc.get('actividad_cronograma'), doc.get('fecha_relevante'), 
                       doc.get('lugar_pago'), doc.get('tasa_soles')]):
                    doc_lines.append("")
                
                # Agregar CONTENIDO
                doc_lines.append(f"üìÑ Informaci√≥n: {doc['content']}")
                
                context_parts.append("\n".join(doc_lines))
            
            # Unir todos los documentos
            context = "\n\n" + "="*70 + "\n\n".join([""] + context_parts) + "\n\n" + "="*70
            
            # DEBUG: Ver qu√© contexto se env√≠a
            logger.info("=" * 80)
            logger.info("üìÑ CONTEXTO ENVIADO AL LLM:")
            logger.info(context[:1000] + "..." if len(context) > 1000 else context)
            logger.info("=" * 80)
            
            prompt = self._build_prompt(query, context)
            
            # Generar respuesta con Ollama
            return self._generate_with_ollama(prompt, context=context)
        
        except Exception as e:
            logger.error(f"Error en generaci√≥n: {e}")
            return "Lo siento, no puedo procesar tu consulta en este momento. Por favor, intenta m√°s tarde."
    
    def get_answer(self, question):
        """M√©todo principal para obtener respuesta"""
        logger.info(f"üîç Nueva consulta: {question}")
        
        # Buscar documentos relevantes
        relevant_docs = self.search_documents(question)
        
        if not relevant_docs:
            return "No encontr√© informaci√≥n relevante para tu consulta. Por favor, reformula tu pregunta."
        
        # Log documentos recuperados
        for i, doc in enumerate(relevant_docs, 1):
            doc_data = doc['documento']
            
            title_parts = []
            
            if doc_data.get('categoria_principal'):
                title_parts.append(doc_data['categoria_principal'])
            
            if doc_data.get('actividad_cronograma'):
                title_parts.append(f"({doc_data['actividad_cronograma']})")
            elif doc_data.get('sub_categoria'):
                title_parts.append(f"({doc_data['sub_categoria']})")
            
            if doc_data.get('id_chunk'):
                title_parts.append(f"[{doc_data['id_chunk']}]")
            
            title = " ".join(title_parts) if title_parts else "Documento sin identificador"
            
            logger.info(f"  {i}. {title}")
            logger.info(f"      Score: {doc['score']:.3f} (Sem: {doc['semantic_score']:.2f}, KW: {doc['keyword_score']:.2f})")
        
        # Generar respuesta
        answer = self.generate_response(question, relevant_docs)
        logger.info(f"‚úÖ Respuesta generada: {len(answer)} caracteres")
        
        return answer


# Instancia global del servicio
rag_service = RAGService()